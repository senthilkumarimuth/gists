{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ddeb64-3db4-4c06-8b72-e7997c3881e5",
   "metadata": {},
   "source": [
    "Word CNN, short for Word Convolutional Neural Network, is a type of convolutional neural network (CNN) architecture specifically designed for natural language processing (NLP) tasks that operate on a word level. Unlike traditional CNNs used for image classification, which operate on pixel values, Word CNNs process text data by treating words as input features.\n",
    "\n",
    "Here's how a typical Word CNN works:\n",
    "\n",
    "Word Embedding: The input text is first converted into dense vector representations using techniques like word embeddings (e.g., Word2Vec, GloVe). Each word is represented by a fixed-length vector, capturing its semantic meaning.\n",
    "\n",
    "Convolutional Layers: Similar to image CNNs, Word CNNs use convolutional layers to extract local patterns or features from the word embeddings. Convolutional filters with small receptive fields slide over the input word embeddings to capture patterns such as word sequences or combinations of words.\n",
    "\n",
    "Pooling Layers: After convolution, pooling layers are applied to reduce the dimensionality of the feature maps and capture the most relevant information. Common pooling operations include max pooling, which takes the maximum value from each feature map, and average pooling, which computes the average value.\n",
    "\n",
    "Fully Connected Layers: The output of the pooling layers is flattened and passed through one or more fully connected layers, followed by activation functions like ReLU (Rectified Linear Unit), to learn complex relationships between the extracted features.\n",
    "\n",
    "Output Layer: The final fully connected layer is connected to the output layer, which generates predictions for the task at hand, such as sentiment analysis, text classification, or named entity recognition.\n",
    "\n",
    "<b>Word CNNs are particularly effective for tasks where <span style=\"color:red\">local word order matters</b></span>, such as text classification and sentiment analysis. They can capture hierarchical patterns and dependencies in text data, making them suitable for a wide range of NLP applications.\n",
    "\n",
    "Example:\n",
    "A Word CNN can be used for sentiment analysis, where the task is to classify the sentiment of a given text (e.g., positive, negative, or neutral). The Word CNN would take the word embeddings of the input text, apply convolutional and pooling layers to extract features, and then use fully connected layers to predict the sentiment category.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf435249-f555-4551-9d8c-972b5232080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 8s 0us/step\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "157/157 [==============================] - 24s 148ms/step - loss: 0.4905 - accuracy: 0.7512 - val_loss: 0.3334 - val_accuracy: 0.8562\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 23s 149ms/step - loss: 0.1939 - accuracy: 0.9295 - val_loss: 0.3147 - val_accuracy: 0.8714\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 23s 148ms/step - loss: 0.0320 - accuracy: 0.9947 - val_loss: 0.3569 - val_accuracy: 0.8724\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 23s 146ms/step - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.3988 - val_accuracy: 0.8694\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 23s 147ms/step - loss: 9.6445e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.8688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22edccd6260>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the IMDb dataset\n",
    "vocab_size = 20000  # Vocabulary size\n",
    "max_len = 100  # Maximum sequence length\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Pad sequences to ensure uniform length\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Define the Word CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(vocab_size, 300, input_length=max_len),  # Embedding layer with word embeddings (300-dimensional)\n",
    "    layers.Conv1D(128, 5, activation='relu'),  # Convolutional layer with 128 filters and kernel size 5\n",
    "    layers.GlobalMaxPooling1D(),  # Global max pooling layer\n",
    "    layers.Dense(64, activation='relu'),  # Dense layer with 64 units\n",
    "    layers.Dense(2, activation='softmax')  # Output layer with softmax activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train-test split for validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=128, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ab10a2-b9d7-4586-a72e-16b74004c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9163171 , 0.08368296]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([x_test[0].reshape(1, -1)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22064f-6378-451b-a260-606513ab9291",
   "metadata": {},
   "source": [
    "Thus it confirms that CNN also can be configured to use for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d1f2f-378f-4dfe-884c-1e4d021234d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
