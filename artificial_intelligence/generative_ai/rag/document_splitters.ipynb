{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdffdbda",
   "metadata": {},
   "source": [
    "# From llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f59ee",
   "metadata": {},
   "source": [
    "In **LlamaIndex**, *splitters* break large documents into manageable text chunks for embedding and retrieval. Here are the main types:\n",
    "\n",
    "---\n",
    "\n",
    "### üß© 1. **`SentenceSplitter`**\n",
    "\n",
    "* Splits text by sentences (using `nltk` or `spacy` internally).\n",
    "* Best for **semantic coherence**.\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìÑ 2. **`TokenTextSplitter`**\n",
    "\n",
    "* Splits based on **token count** (useful when working with OpenAI or local LLMs).\n",
    "* Helps avoid exceeding model token limits.\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "splitter = TokenTextSplitter(separator=\" \", chunk_size=256, chunk_overlap=20)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ü™∂ 3. **`MarkdownSplitter`**\n",
    "\n",
    "* Keeps markdown structure like headers, lists, and code blocks intact.\n",
    "* Ideal for **technical docs or README files**.\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "splitter = MarkdownNodeParser()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìö 4. **`SemanticSplitter`**\n",
    "\n",
    "* Uses embeddings to split text **based on semantic similarity**, not just size.\n",
    "* More intelligent, but computationally heavier.\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "splitter = SemanticSplitterNodeParser(embed_model=\"text-embedding-3-small\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîñ 5. **`HierarchicalNodeParser`**\n",
    "\n",
    "* Creates a **multi-level structure** (paragraphs ‚Üí sections ‚Üí chapters).\n",
    "* Useful for large books, reports, or PDFs.\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "splitter = HierarchicalNodeParser.from_defaults()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è 6. **`CodeSplitter`**\n",
    "\n",
    "* Specialized for **source code** ‚Äì respects functions, classes, and imports.\n",
    "\n",
    "```python\n",
    "from llama_index.core.node_parser import CodeSplitter\n",
    "splitter = CodeSplitter(language=\"python\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to show a **side-by-side example** of how the same document is split differently by each splitter?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97b4b1",
   "metadata": {},
   "source": [
    "# From langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ae515",
   "metadata": {},
   "source": [
    "In **LangChain**, document splitters are in the module\n",
    "`langchain.text_splitter`. Here are the main types you can use:\n",
    "\n",
    "---\n",
    "\n",
    "### üß± 1. **`CharacterTextSplitter`**\n",
    "\n",
    "* Splits by character count (simple and fast).\n",
    "* Default separator: `\"\\n\\n\"`.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=1000, chunk_overlap=100)\n",
    "docs = splitter.split_text(long_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÇÔ∏è 2. **`RecursiveCharacterTextSplitter`** *(most popular)*\n",
    "\n",
    "* Tries multiple separators (like `\\n\\n`, `.`, `,`, ` `) to split cleanly.\n",
    "* Keeps semantic context better.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = splitter.split_text(long_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìò 3. **`TokenTextSplitter`**\n",
    "\n",
    "* Splits based on **tokens** (not characters).\n",
    "* Prevents overflow for LLM input limits.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "splitter = TokenTextSplitter(chunk_size=256, chunk_overlap=20)\n",
    "docs = splitter.split_text(long_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ü™∂ 4. **`MarkdownHeaderTextSplitter`**\n",
    "\n",
    "* Splits Markdown docs by header levels (`#`, `##`, etc.).\n",
    "* Keeps hierarchical context.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(headers_to_split_on=[(\"#\", \"Header 1\"), (\"##\", \"Header 2\")])\n",
    "docs = splitter.split_text(markdown_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üíª 5. **`PythonCodeTextSplitter`**\n",
    "\n",
    "* Splits Python code by **function**, **class**, or **logical blocks**.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import PythonCodeTextSplitter\n",
    "\n",
    "splitter = PythonCodeTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_text(python_code)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† 6. **`NLTKTextSplitter` / `SpacyTextSplitter`**\n",
    "\n",
    "* Sentence-based splitting using NLP libraries.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "\n",
    "splitter = SpacyTextSplitter(chunk_size=1000)\n",
    "docs = splitter.split_text(long_text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Summary\n",
    "\n",
    "| Splitter                         | Best for      | Key Feature            |\n",
    "| -------------------------------- | ------------- | ---------------------- |\n",
    "| `CharacterTextSplitter`          | Simple text   | Fast & straightforward |\n",
    "| `RecursiveCharacterTextSplitter` | General use   | Context-aware          |\n",
    "| `TokenTextSplitter`              | LLM inputs    | Token-limit control    |\n",
    "| `MarkdownHeaderTextSplitter`     | Docs / README | Preserves structure    |\n",
    "| `PythonCodeTextSplitter`         | Code files    | Logical code splitting |\n",
    "| `SpacyTextSplitter`              | Natural text  | Sentence-aware         |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to show an example comparing `RecursiveCharacterTextSplitter` vs `MarkdownHeaderTextSplitter` on the same text?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
